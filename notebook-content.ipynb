{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Pipeline Demo\n",
    "Configure sys.path, load your dataframes, and run discovery → validation → profiling/feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup import path (adjust if you relocate the project)\n",
    "import sys, os\n",
    "PROJECT_ROOT = '/Users/jacknnewman/Desktop/Smart_flow'\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Optional: install deps if the kernel lacks them\n",
    "# !pip install -r f'{PROJECT_ROOT}/requirements.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from smart_pipeline import run_pipeline_on_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace with your real loads (CSV/read_sql/etc.)\n",
    "header_df = pd.DataFrame([\n",
    "    {'OrderID': 'SO1', 'OrderDate': '2023-01-01', 'TotalAmount': 150.0},\n",
    "    {'OrderID': 'SO2', 'OrderDate': '2023-01-02', 'TotalAmount': 300.0},\n",
    "])\n",
    "\n",
    "line_df = pd.DataFrame([\n",
    "    {'OrderID': 'SO1', 'LineDate': '2023-01-01', 'LineAmount': 50.0},\n",
    "    {'OrderID': 'SO1', 'LineDate': '2023-01-01', 'LineAmount': 100.0},\n",
    "    {'OrderID': 'SO2', 'LineDate': '2023-01-02', 'LineAmount': 200.0},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base configuration and overrides (single line table)\n",
    "config_dict = {\n",
    "    'profiling': {'enabled': False},  # set True to render plots\n",
    "    'feature_engineering': {'enabled': True, 'lag_periods': [1, 7], 'rolling_windows': [7]},\n",
    "}\n",
    "\n",
    "overrides = {\n",
    "    'join_key': {'header': 'OrderID', 'line': 'OrderID'},\n",
    "    'header': {'date': 'OrderDate', 'amount': 'TotalAmount'},\n    "    'line': {'date': 'LineDate', 'amount': 'LineAmount'},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline\n",
    "df, context, validation = run_pipeline_on_dfs(\n",
    "    header_df,\n",
    "    line_df,\n",
    "    config_dict=config_dict,\n",
    "    overrides=overrides,\n",
    ")\n",
    "\n",
    "display(df.head())\n",
    "print('Context:', context)\n",
    "print('Validation:')\n",
    "for v in validation:\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-line tables example (optional).\n",
    "# Provide extra line tables in config and per-table overrides when needed.\n",
    "cfg_multi = {\n",
    "    'sources': {\n",
    "        'header_table': 'headers',\n",
    "        'line_table': 'line_items',\n",
    "        'line_tables': ['line_items', 'line_items_returns', 'line_items_adjustments'],\n",
    "    },\n",
    "    'profiling': {'enabled': False},\n",
    "    'feature_engineering': {'enabled': True},\n",
    "}\n",
    "over_multi = {\n",
    "    'join_key': {'header': 'OrderID', 'line': 'OrderID'},\n",
    "    'per_line': {\n",
    "        'line_items_returns': {'amount': 'ReturnAmount'},\n",
    "        'line_items_adjustments': {'amount': 'AdjustAmount'},\n",
    "    },\n",
    "}\n",
    "# Uncomment to run multi-line scenario (requires those tables to exist)\n",
    "# df_multi, ctx_multi, val_multi = run_pipeline_on_dfs(header_df, line_df, config_dict=cfg_multi, overrides=over_multi)\n",
    "# display(df_multi.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: persist outputs locally\n",
    "import pathlib, json\n",
    "out_dir = pathlib.Path(PROJECT_ROOT) / 'logs'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "df.reset_index().to_parquet(out_dir / 'aggregated.parquet', index=False)\n",
    "meta = {'context': context, 'validation': [getattr(v, '__dict__', str(v)) for v in validation]}\n",
    "(out_dir / 'run_meta.json').write_text(json.dumps(meta, indent=2), encoding='utf-8')\n",
    "print('Saved to', out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
